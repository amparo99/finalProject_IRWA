{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython \n",
    "from nbformat import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/anaconda3/lib/python3.7/site-packages (1.1.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amparoalias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "path = os.path.dirname(os.path.realpath('ex2'))\n",
    "import sys \n",
    "sys.path.insert (0, path) \n",
    "import searchEngine as se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Dec 17 18:23:49 +0000 2020</td>\n",
       "      <td>1339637441238454273</td>\n",
       "      <td>1339637441238454273</td>\n",
       "      <td>I’ve seen a huge amount of people pleading to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 256]</td>\n",
       "      <td>{'hashtags': [{'text': 'BLM', 'indices': [252,...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Thu Dec 17 18:23:49 +0000 2020  1339637441238454273  1339637441238454273   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  I’ve seen a huge amount of people pleading to ...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0           [0, 256]  {'hashtags': [{'text': 'BLM', 'indices': [252,...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "\n",
       "   ... quoted_status_id  quoted_status_id_str retweet_count favorite_count  \\\n",
       "0  ...              NaN                   NaN             0              0   \n",
       "\n",
       "  favorited retweeted lang extended_entities possibly_sensitive quoted_status  \n",
       "0     False     False   en               NaN                NaN           NaN  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = se.df_tweets\n",
    "df_tweets.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model of word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(window=5, min_count=1, workers=4,size=10)\n",
    "\n",
    "tweets_cleaned = [se.getTerms(text) for text in df_tweets[\"full_text\"]]\n",
    "model.build_vocab(tweets_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2289428, 2528250)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(tweets_cleaned,total_examples=len(tweets_cleaned),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation of tweets and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet2vec(text,word2vec):\n",
    "    for i,word in enumerate(text):\n",
    "        #print(word)\n",
    "    \n",
    "        word_vector = word2vec[word]\n",
    "        #print(word_vector.shape)\n",
    "        if i  > 0:\n",
    "            vectors = np.concatenate([vectors,word_vector])\n",
    "        if i == 0:\n",
    "            vectors = word_vector  \n",
    "    return vectors.reshape(len(text),-1).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2vec(query, word2vec):\n",
    "    query=se.getTerms(query)\n",
    "    for i,word in enumerate(query):\n",
    "    \n",
    "        word_vector = word2vec[word]\n",
    "        if i  > 0:\n",
    "            vectors = np.concatenate([vectors,word_vector])\n",
    "        if i == 0:\n",
    "            vectors = word_vector  \n",
    "    return vectors.reshape(len(query),-1).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "representation = [tweet2vec(items,model) for items in tweets_cleaned]\n",
    "embeded_tweets = np.array(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=250, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embeded_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=CLUSTERS, random_state=0,max_iter=1000).fit(embeddings_en_2d)\n",
    "df_tweets[\"cluster\"] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversify_score(df_tweets,num_clusters=5):\n",
    "    '''Returs the diversify score for a given set of tweets,\n",
    "    input must be a df with the field of cluster defined'''\n",
    "    #print(np.unique(df_tweets.cluster.values,return_counts=True))\n",
    "    score = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        cluster_items = len(df_tweets[df_tweets.cluster==i])\n",
    "        if  cluster_items > 0:\n",
    "            # For each cluster, the query can have a score up to 1.\n",
    "            individual_score = 1 if cluster_items/(len(df_tweets)/num_clusters) > 1 else cluster_items/(len(df_tweets)/num_clusters)\n",
    "            #print(individual_score)\n",
    "            score = individual_score*(1/num_clusters) + score\n",
    "            #print(df_tweets[df_tweets.cluster==i].shape[0])\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversify_correction(results,top):\n",
    "    new_df = pd.DataFrame(columns = results.columns)\n",
    "    residue,integer = math.modf(top/CLUSTERS)\n",
    "    #print(math.modf(top/CLUSTERS))\n",
    "    residue = np.round(residue/CLUSTERS)\n",
    "    for i in range(int(integer)):\n",
    "        for cluster in range(CLUSTERS):\n",
    "            #print(results[results.cluster==cluster].shape)\n",
    "            if results[results.cluster==cluster].shape[0] > i:\n",
    "                new_df =new_df.append(results[results.cluster==cluster].iloc[i])\n",
    "            else:\n",
    "                pass\n",
    "    for i in range(int(residue)):\n",
    "         new_df =new_df.append(results[results.cluster==cluster].iloc[i])\n",
    "    return new_df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userInteraction():\n",
    "    print(\"Insert: \\n1 if you want to use the inverted index \\n2 if you want to use our score,\\n3 if you want to return a more diverse output\")\n",
    "    scoring = input()\n",
    "    scoring = int(scoring)\n",
    "\n",
    "    print(\"\\nHow many returned tweets you want?\")\n",
    "    \n",
    "    top = input()\n",
    "    top = int(top)\n",
    "\n",
    "    print(\"\\nInsert your query:\")\n",
    "    query_input = input()\n",
    "    \n",
    "    ranked_docs = se.search_tweets(query_input, se.index, scoring)      \n",
    "    \n",
    "    print(\"\\n======================\\nTop {} results out of {} for the searched query:\\n\".format(top, len(ranked_docs)))\n",
    "    results = pd.DataFrame(columns=['for_query','tweet', 'username', 'date', 'hashtags', 'likes', 'retweets', 'url','cluster'])\n",
    "    count = 0\n",
    "    \n",
    "    for d_id in ranked_docs:\n",
    "        results.loc[count,'for_query'] = query_input\n",
    "        results.loc[count,'tweet'] = df_tweets.loc[d_id, \"full_text\"]\n",
    "        results.loc[count,'username'] = df_tweets.loc[d_id, \"user\"]['screen_name']\n",
    "        results.loc[count,'date'] = df_tweets.loc[d_id, \"created_at\"]\n",
    "        results.loc[count,'hashtags'] = [df_tweets.loc[0,'entities']['hashtags'][i]['text'] for i in range(len(df_tweets.loc[0,'entities']['hashtags']))]\n",
    "        results.loc[count,'likes'] = df_tweets.loc[d_id, \"favorite_count\"]\n",
    "        results.loc[count,'retweets'] = df_tweets.loc[d_id, \"retweet_count\"]\n",
    "        results.loc[count,'cluster'] = df_tweets.loc[d_id, \"cluster\"]\n",
    "        results.loc[count,'url'] = \"https://twitter.com/twitter/statuses/\"+str(df_tweets.loc[d_id, \"id\"])\n",
    "        count +=1\n",
    "    \n",
    "\n",
    "    if scoring  == 3:\n",
    "        results = diversify_correction(results,top)\n",
    "        print(\"the diversity score obtained is \",diversify_score(results))\n",
    "    else:\n",
    "        print(\"the diversity score obtained is \",diversify_score(results[:top]))        \n",
    "    \n",
    "    return results[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalresults = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert: \n",
      "1 if you want to use the inverted index \n",
      "2 if you want to use our score,\n",
      "3 if you want to return a more diverse output\n",
      "3\n",
      "\n",
      "How many returned tweets you want?\n",
      "10\n",
      "\n",
      "Insert your query:\n",
      "All lives matter\n",
      "\n",
      "Doing the ranking.. \n",
      "\n",
      "======================\n",
      "Top 10 results out of 399 for the searched query:\n",
      "\n",
      "the diversity score obtained is  0.4\n"
     ]
    }
   ],
   "source": [
    "results = userInteraction()\n",
    "totalresults = totalresults.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalresults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalresults.to_csv(\"../other_outputs/rq2a-with.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
